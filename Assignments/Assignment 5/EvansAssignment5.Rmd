---
title: 'ECOL 8890: Assignment 5'
author: "Michelle Evans"
date: "November 11, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(MASS)
library(nlme)
library(pgirmess)
library(geosphere)
```


```{r data formatting}
treeData <- read.csv("SNP_TC_change1.csv", stringsAsFactors = F)
#rescale location data
treeData$XScaled <- scale(treeData$X, center = T, scale = T)
treeData$YScaled <- scale(treeData$Y, center = T, scale = T)
```

```{r, echo = F}
unscale <- function(var, column){
  varOld <- var * sd(column) + mean(column)
  return(varOld)
}
```


# 1

Produce variograms for MAP and FIRE. Test for significant spatial autocorrelation using Moranâ€™s I. What is the range of the spatial autocorrelation of the model residuals?

```{r MAP variogram}
par(mfrow = c(2,1))
MAPvar <- with(treeData, data.frame(correlog(coords = cbind(XScaled, YScaled), z = MAP, method = "Moran")))
plot(MAPvar$dist.class, MAPvar$coef, type = "l", xlab = "Lag distance", ylab = "Moran I")
mtext("Variogram of MAP")
abline(h=0, col="red")

FIREvar <- with(treeData, data.frame(correlog(coords = cbind(XScaled, YScaled), z = FIRE, method = "Moran")))
plot(FIREvar$dist.class, FIREvar$coef, type = "l", xlab = "Lag distance", ylab = "Moran I")
mtext("Variogram of FIRE")
abline(h=0, col="red")
```

Both of the variables are autocorrelated until about 1 - 1.5 rescaled distance units away.

# 2

Fit two models relating woody cover change (WCI) to MAP and FIRE using gls, one with and one without spatial autocorrelation. Compare them with a Likelihood Ratio test.

```{r}
mod1 <- gls(WCI ~ MAP + FIRE,
            data = treeData)

plot(Variogram(mod1, resType = "n", form = ~XScaled + YScaled), main = "No Autocorrelation")


modExp <- gls(WCI ~ MAP + FIRE,
              correlation = corExp(form = ~XScaled + YScaled),
              data = treeData)

plot(Variogram(modExp, resType = "n", form = ~XScaled + YScaled), main = "Exponential")

knitr::kable(anova(mod1, modExp))
```

The model with spatial autocorrelation `modExp` has a higher log-Likelihood (138.67 vs. 124.270). It's semivariogram also begins at 1 and is flat, compared to the model without spatial autocorrelation that increases with distance.

# 3

Fit the same model again, but test alternative autocorrelation functions (Spherical, Exponential). Do some fit better than others? How do the semivariograms change?

```{r}
modLin <- gls(WCI ~ MAP + FIRE,
              correlation = corLin(form = ~XScaled + YScaled),
              data = treeData)

modSpher <- gls(WCI ~ MAP + FIRE,
              correlation = corSpher(form = ~XScaled + YScaled),
              data = treeData)

modGauss<- gls(WCI ~ MAP + FIRE,
              correlation = corGaus(form = ~XScaled + YScaled),
              data = treeData)

```

```{r}
par(mfrow=c(3,2))

plot(Variogram(mod1, resType = "n", form = ~XScaled + YScaled), main = "No Autocorrelation")

plot(Variogram(modExp, resType = "n", form = ~XScaled + YScaled), main = "Exponential")

plot(Variogram(modLin, resType = "n", form = ~XScaled + YScaled), main = "Linear")

plot(Variogram(modSpher, resType = "n", form = ~XScaled + YScaled), main = "Spherical")

plot(Variogram(modGauss, resType = "n", form = ~XScaled + YScaled), main = "Gaussian")

```

```{r}
knitr::kable(anova(mod1, modExp, modLin, modSpher, modGauss))
```

There isn't a huge difference between most of the autocorrelation functions. The gaussian is visibly worse, and fits worse than the others, but the exponential and spherical fit similarly. The exponential fits marginally better, however.

# 4 

Conduct a model selection exercise using gls. What is the top model? Examine the semivariogram of your top model using normalized residuals. Does your model do a good job accounting for autocorrelation?

```{r}
MuMIn::Weights(AIC(mod1, modExp, modLin, modSpher, modGauss))
```

An AIC weighting scheme identifies the model with the exponential spatial autocorrelation as having the best fit, receiving baout 61% of the weight. All of the semivariograms above were using normalized residuals. The line is flat and starts at the maximum value, so I think this autocorrelation function performs well.

# 5

Now rerun your models in an OLS framework by thinning your data set. You previously estimated the range of the semivariogram for one of your models. Thin your data using sample so that on average any two points are at least this distance apart. How might you do this?

```{r thin data}

distance <- as.matrix(dist(cbind(treeData$XScaled, treeData$YScaled), diag = T))
diag(distance) <- NA

#based on thinning algorithm from spThin package
treeThin <- treeData
while(min(distance, na.rm = T) < 1.3 & nrow(treeThin) > 1){ #loop until each one is gone
  nearNb <- which(distance < 1.3, arr.ind = T)[,1]
  toRemove <- as.numeric(names(which(table(nearNb) == max(table(nearNb))))) #drop that point which is closest to the most points
  if (length(toRemove) > 1){
    toRemove <- sample(toRemove, 1)
  }
  treeThin <- treeThin[-toRemove,]
  distance <- distance[-toRemove,-toRemove]
}  
```

This results in a very small data frame of only 7 samples.

```{r}
modThin <- gls(WCI ~ MAP + FIRE,
            data = treeThin)

summary(modThin)

plot(Variogram(modThin, resType = "n", form = ~XScaled + YScaled), main = "No Autocorrelation")
```

